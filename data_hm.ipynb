{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from huggingface_hub import HfApi, snapshot_download, hf_hub_download\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download hm data from kaggle\n",
    "# !kaggle competitions download -c h-and-m-personalized-fashion-recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ./h-and-m-personalized-fashion-recommendations.zip -d ./raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "seed = 42\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_pickle(data, path):\n",
    "    with open(path, \"wb\") as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def dump_json(data, path):\n",
    "    with open(path, \"w\") as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_pt(data, path):\n",
    "    with open(path, \"wb\") as file:\n",
    "        torch.save(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_dir(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "\n",
    "\n",
    "def get_timestamp(date_format: str = \"%d%H%M%S\") -> str:\n",
    "    timestamp = datetime.now()\n",
    "    return timestamp.strftime(date_format)\n",
    "\n",
    "\n",
    "n_core = 15\n",
    "data_dir = f\"./data/HM\"\n",
    "mk_dir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = pd.read_csv(f\"{data_dir}/articles.csv\")\n",
    "interaction_data = pd.read_csv(f\"{data_dir}/transactions_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_equal = interaction_data.equals(\n",
    "    interaction_data.sort_values(by=[\"t_dat\", \"customer_id\"], axis=0).reset_index(\n",
    "        drop=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx = []\n",
    "\n",
    "for idx in tqdm(range(1, len(interaction_data))):\n",
    "    if interaction_data.iloc[idx - 1].equals(interaction_data.iloc[idx]):\n",
    "        drop_idx.append(idx)\n",
    "\n",
    "interaction_data = interaction_data.drop(index=drop_idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item_data = item_data.dropna(axis=0, how=\"any\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_by_id(df, article_id: int, no_list: list, echo: int = 1, img_show: bool = True):\n",
    "    if article_id in no_list:\n",
    "        return\n",
    "    if echo:\n",
    "        display(df[df.article_id == article_id])\n",
    "\n",
    "    img_id = \"0\" + str(article_id)\n",
    "    img = Image.open(f\"{data_dir}/images/\" + img_id[0:3] + \"/\" + img_id + \".jpg\")\n",
    "\n",
    "    if img_show:\n",
    "        img.show()\n",
    "\n",
    "\n",
    "def find_no_img_item(df):\n",
    "    no_img = []\n",
    "\n",
    "    for item in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            img_by_id(df, item[1][0], no_list=no_img, echo=0, img_show=False)\n",
    "        except:\n",
    "            no_img.append(item[0])\n",
    "\n",
    "    return no_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_img_idx = find_no_img_item(n_item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of non-img item : \", len(no_img_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item_data = n_item_data.drop(index=no_img_idx, axis=0).reset_index(drop=True)\n",
    "print(\"shape of n_item_data : \", n_item_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_interaction_data = interaction_data[\n",
    "    interaction_data[\"article_id\"].isin(n_item_data[\"article_id\"])\n",
    "].reset_index(drop=True)\n",
    "print(\"shape of interaction data : \", interaction_data.shape)\n",
    "print(\"shape of n_interaction_data : \", n_interaction_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_checker(df, group, target, threshold):\n",
    "    counter = df.groupby(group)[target].nunique()\n",
    "    valid = counter[counter >= threshold].index\n",
    "    return df[df[group].isin(valid)]\n",
    "\n",
    "\n",
    "def data_cutter(origin_data, u_core, i_core):\n",
    "    print(\"### before ###\")\n",
    "    print(\"shape of n_interaction_data : \", origin_data.shape)\n",
    "\n",
    "    while True:\n",
    "        new_data = core_checker(origin_data, \"customer_id\", \"article_id\", u_core)\n",
    "        new_data = core_checker(new_data, \"article_id\", \"customer_id\", i_core)\n",
    "\n",
    "        if new_data.equals(origin_data):\n",
    "            print(\"finish\")\n",
    "            break\n",
    "\n",
    "        origin_data = new_data\n",
    "\n",
    "    print(\"### after all item sampled ###\")\n",
    "    print(f\"### user_core : {u_core}, item_core : {i_core} ###\")\n",
    "    print(\"shape of n_interaction_data : \", new_data.shape)\n",
    "    print(\"num of user : \", new_data.customer_id.nunique())\n",
    "    print(\"num of item : \", new_data.article_id.nunique())\n",
    "    print(\n",
    "        \"data density : \",\n",
    "        new_data.shape[0]\n",
    "        / (new_data.customer_id.nunique() * new_data.article_id.nunique())\n",
    "        * 100,\n",
    "        \"%\",\n",
    "    )\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_core = 15\n",
    "item_core = 10\n",
    "core_inter_data = data_cutter(n_interaction_data, 15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_interaction_data = core_inter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"shape of interaction data\": new_interaction_data.shape,\n",
    "    \"user_core\": user_core,\n",
    "    \"item_core\": item_core,\n",
    "    \"shape of unique_data\": new_interaction_data.shape,\n",
    "    \"num of user\": new_interaction_data.customer_id.nunique(),\n",
    "    \"num of item\": new_interaction_data.article_id.nunique(),\n",
    "    \"data density\": f\"{new_interaction_data.shape[0]/(new_interaction_data.customer_id.nunique()*new_interaction_data.article_id.nunique())*100}%\",\n",
    "}\n",
    "\n",
    "dump_json(metadata, f\"{data_dir}/metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item_data = n_item_data[\n",
    "    n_item_data[\"article_id\"].isin(new_interaction_data[\"article_id\"])\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fashion_clip.fashion_clip import FashionCLIP\n",
    "\n",
    "fclip = FashionCLIP(\"fashion-clip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\n",
    "    f\"{data_dir}/images/\" + \"0\" + str(k)[0:2] + \"/\" + \"0\" + str(k) + \".jpg\"\n",
    "    for k in n_item_data[\"article_id\"].tolist()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fclip = fclip.encode_images(images, batch_size=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {article_id : emb}\n",
    "id_img_emb_map = {\n",
    "    k: torch.tensor(v) for k, v in zip(n_item_data[\"article_id\"].tolist(), image_fclip)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item_data[\"prod_name\"] = n_item_data[\"prod_name\"].fillna(\" \")\n",
    "n_item_data[\"detail_desc\"] = n_item_data[\"detail_desc\"].fillna(\" \")\n",
    "n_item_data[\"colour_group_name\"] = n_item_data[\"colour_group_name\"].fillna(\" \")\n",
    "n_item_data[\"graphical_appearance_name\"] = n_item_data[\n",
    "    \"graphical_appearance_name\"\n",
    "].fillna(\" \")\n",
    "\n",
    "n_item_data[\"prod_name\"] = n_item_data[\"prod_name\"].replace(\"Unknown\", \" \")\n",
    "n_item_data[\"detail_desc\"] = n_item_data[\"detail_desc\"].replace(\"Unknown\", \" \")\n",
    "n_item_data[\"colour_group_name\"] = n_item_data[\"colour_group_name\"].replace(\n",
    "    \"Unknown\", \" \"\n",
    ")\n",
    "n_item_data[\"graphical_appearance_name\"] = n_item_data[\n",
    "    \"graphical_appearance_name\"\n",
    "].replace(\"Unknown\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item_data[\"desc\"] = n_item_data.apply(\n",
    "    lambda x: f\"{x['detail_desc'][:100]} {x[\"colour_group_name\"][:100]} {x['graphical_appearance_name'][:100]}\",\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = n_item_data[\"desc\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_fclip = fclip.encode_text(texts, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {article_id : emb}\n",
    "id_text_emb_map = {\n",
    "    k: torch.tensor(v) for k, v in zip(n_item_data[\"article_id\"].tolist(), text_fclip)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2idx = {\n",
    "    v: k for k, v in enumerate(new_interaction_data[\"customer_id\"].unique())\n",
    "}  # {customer_id:idx}\n",
    "item2idx = {\n",
    "    v: k for k, v in enumerate(n_item_data[\"article_id\"].unique())\n",
    "}  # {item_id:idx}\n",
    "\n",
    "print(\"# of user\", len(user2idx))\n",
    "print(\"# of item\", len(item2idx))\n",
    "\n",
    "torch.save(item2idx, f\"{data_dir}/item2idx.pt\")\n",
    "torch.save(user2idx, f\"{data_dir}/user2idx.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_img_emb_map = {\n",
    "    item2idx[row[\"article_id\"]]: id_img_emb_map[row[\"article_id\"]]\n",
    "    for _, row in tqdm(n_item_data.iterrows(), total=len(n_item_data))\n",
    "}\n",
    "idx_text_emb_map = {\n",
    "    item2idx[row[\"article_id\"]]: id_text_emb_map[row[\"article_id\"]]\n",
    "    for _, row in tqdm(n_item_data.iterrows(), total=len(n_item_data))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(idx_img_emb_map, f\"{data_dir}/idx_img_emb_map.pt\")\n",
    "torch.save(idx_text_emb_map, f\"{data_dir}/idx_text_emb_map.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_meta_map = {\n",
    "    item2idx[row[\"article_id\"]]: row[\"text\"] for _, row in n_item_data.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item_data = n_item_data[[\"article_id\"]]\n",
    "new_interaction_data = new_interaction_data[[\"customer_id\", \"article_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_interaction_data[\"customer_id\"] = new_interaction_data[\"customer_id\"].map(user2idx)\n",
    "new_interaction_data[\"article_id\"] = new_interaction_data[\"article_id\"].map(item2idx)\n",
    "n_item_data[\"article_id\"] = n_item_data[\"article_id\"].map(item2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train/valid/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data = new_interaction_data.drop_duplicates(\n",
    "    [\"article_id\", \"customer_id\"], keep=\"last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"shape of interaction data\": unique_data.shape,\n",
    "    \"user_core\": 15,\n",
    "    \"item_core\": 10,\n",
    "    \"num of user\": unique_data.customer_id.nunique(),\n",
    "    \"num of item\": unique_data.article_id.nunique(),\n",
    "    \"data density\": f\"{unique_data.shape[0]/(unique_data.customer_id.nunique()*unique_data.article_id.nunique())*100}%\",\n",
    "}\n",
    "\n",
    "dump_json(metadata, f\"{data_dir}/uniqued_metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "test_data = dict(unique_data.groupby(\"customer_id\")[\"article_id\"].progress_apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [v for v in test_data.values()]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_data, f\"{data_dir}/uniqued_test_data.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
